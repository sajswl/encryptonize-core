# Minimal setup for a ceph cluster that automatically provisions storage disks.
# Resource limits are set according to minimum recommandations found here:
# https://docs.ceph.com/en/latest/start/hardware-recommendations/

apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  # General settings
  cephVersion:
    image: ceph/ceph:v15.2.5
    allowUnsupported: false
  dataDirHostPath: /var/lib/rook

  # Cluster wide resource requests/limits
  # resources:
  #   mon:
  #     limits:
  #       cpu: "3000m"
  #       memory: "28Gi"
  #     requests: # Minimum recommended
  #       cpu: "2000m"
  #       memory: "24Gi"
  #   osd:
  #     limits:
  #       cpu: "1500m"
  #       memory: "5Gi"
  #     requests: # Minimum recommended
  #       cpu: "1000m"
  #       memory: "4Gi"

  # ceph-mon settings
  mon:
    count: 3
    allowMultiplePerNode: false
    # PV claim for ceph-mons
    volumeClaimTemplate:
      spec:
        resources:
          requests:
            storage: 60Gi # Mininmum recommended

  # ceph-mgr settings
  mgr:
    modules:
    # Tune the number of placemnet groups automatically
    - name: pg_autoscaler
      enabled: true

  # Enable ceph dashboard
  dashboard:
    enabled: true
    ssl: true

  # Storage settings
  storage:
    storageClassDeviceSets:
    - name: set1
      count: 3 # The number of OSDs
      portable: true
      tuneDeviceClass: true
      encrypted: false

      # Note that the object store requires that there is only one OSD per node, as the failure
      # domain is set to "host" in object.yaml
      placement:
        # Place one OSD pod per node
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - rook-ceph-osd
            topologyKey: kubernetes.io/hostname
      preparePlacement:
        # Place one OSD prepare pod per node
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - rook-ceph-osd-prepare
            topologyKey: kubernetes.io/hostname

      # Automatically provision disk for OSDs
      volumeClaimTemplates:
      - metadata:
          name: data
        spec:
          resources:
            requests:
              storage: 1Ti # Size of each disk
          volumeMode: Block
          accessModes:
            - ReadWriteOnce
